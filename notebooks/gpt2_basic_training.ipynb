{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b263e8cd",
   "metadata": {},
   "source": [
    "# gpt2_basic_training\n",
    "## 2025DEC08\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f42b58",
   "metadata": {},
   "source": [
    "## 1. package loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cd6f3022",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import tiktoken\n",
    "from pathlib import Path\n",
    "import torch\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.ticker import MaxNLocator\n",
    "from datetime import datetime\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import json\n",
    "from copy import deepcopy\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18185ddd",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6a449902",
   "metadata": {},
   "source": [
    "## 2. setup paths for llm package load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bab9e09e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/markb/llm-from-scratch/src\n"
     ]
    }
   ],
   "source": [
    "\n",
    "PROJECT_ROOT = Path().resolve().parents[0]          # -> .../project_root\n",
    "SRC_DIR = PROJECT_ROOT / \"src\"           # -> .../project_root/src\n",
    "print(SRC_DIR)\n",
    "\n",
    "if str(SRC_DIR) not in sys.path:\n",
    "    sys.path.insert(0, str(SRC_DIR))\n",
    "\n",
    "from llm_from_scratch.configs import gpt2small_config\n",
    "from llm_from_scratch.training import training_utils\n",
    "from llm_from_scratch.models import gpt2\n",
    "from llm_from_scratch.dataloader import dataloader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4333239c",
   "metadata": {},
   "source": [
    "## 3. setup run_training()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4457b726",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(cfg):\n",
    "    \"\"\"Run a single training experiment given a config dict.\"\"\"\n",
    "    cfg = deepcopy(cfg)  # avoid in-place mutation\n",
    "\n",
    "    model_cfg = cfg['model_config']\n",
    "\n",
    "    # adjust device if cuda not available and cuda was chosen\n",
    "    device = cfg['device_name']\n",
    "    print(\"DEVICE: initial device before adjustment:\",device)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    print(\"DEVICE: device AFTER adjustment:\",str(device))\n",
    "    cfg['device_name'] = str(device)\n",
    "    \n",
    "    torch.manual_seed(cfg['seed'])\n",
    "    print(cfg)\n",
    "    # modify cfg)\n",
    "    # setup model\n",
    "    model = gpt2.setup_model(model_cfg)\n",
    "    model.to(device)\n",
    "    totparams = sum(p.numel() for p in model.parameters())\n",
    "    print(\"Total number of parameters:\", totparams)\n",
    "\n",
    "    # DEBUG: check model\n",
    "    print(\"weight_tying flag:\", model_cfg[\"weight_tying\"])\n",
    "    print(\"same object?:\", model.out_head.weight is model.tok_emb.weight)\n",
    "    print(\"out_head.weight shape:\", model.out_head.weight.shape)\n",
    "    print(\"tok_emb.weight shape:\", model.tok_emb.weight.shape)\n",
    "\n",
    "\n",
    "    # tokenizer\n",
    "    tokenizer = tiktoken.get_encoding(cfg['tokenizer'])\n",
    "\n",
    "    # dataloaders\n",
    "    train_loader, val_loader, test_loader = dataloader.generate_data_loaders(cfg)\n",
    "    print(\"Show train_loader first entry (converted to text):\")\n",
    "    dataloader.loader_text_examine(train_loader, 0, tokenizer)\n",
    "    print(\"Show val_loader first entry (converted to text):\")\n",
    "    dataloader.loader_text_examine(val_loader, 0, tokenizer)\n",
    "    if test_loader is not None:\n",
    "        print(\"Show test_loader first entry (converted to text):\")\n",
    "        dataloader.loader_text_examine(test_loader, 0, tokenizer)\n",
    "    \n",
    "    # DEBUG: check\n",
    "    # get one batch\n",
    "    # input_batch, target_batch = next(iter(train_loader))\n",
    "    # input_batch = input_batch.to(device)\n",
    "    # target_batch = target_batch.to(device)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     logits = model(input_batch)\n",
    "\n",
    "    # print(\"tok_emb weight: mean, std:\",\n",
    "    #     model.tok_emb.weight.mean().item(),\n",
    "    #     model.tok_emb.weight.std().item())\n",
    "    # print(\"out_head weight: mean, std:\",\n",
    "    #     model.out_head.weight.mean().item(),\n",
    "    #     model.out_head.weight.std().item())\n",
    "\n",
    "    # print(\"embeds std:\", model.tok_emb(input_batch).std().item())\n",
    "    # print(\"logits: mean, std, min, max:\",\n",
    "    #     logits.mean().item(),\n",
    "    #     logits.std().item(),\n",
    "    #     logits.min().item(),\n",
    "    #     logits.max().item())\n",
    "\n",
    "\n",
    "    # training loop\n",
    "    model.train()\n",
    "    num_epochs = cfg['num_epochs']\n",
    "    optimizer = training_utils.setup_optimizer(model, cfg)\n",
    "    train_losses, val_losses, tokens_seen, global_step = training_utils.train_model_simple(\n",
    "        model=model,\n",
    "        train_loader=train_loader,\n",
    "        val_loader=val_loader,\n",
    "        optimizer=optimizer,\n",
    "        device=cfg['device_name'],\n",
    "        num_epochs=cfg['num_epochs'],\n",
    "        eval_freq=5,\n",
    "        eval_iter=5,\n",
    "        start_context=\"Every effort moves you\",\n",
    "        tokenizer=tokenizer\n",
    "    )\n",
    "\n",
    "    # plot and save plot\n",
    "    epochs_tensor = torch.linspace(0, cfg['num_epochs'], len(train_losses))\n",
    "    training_utils.plot_losses(cfg, epochs_tensor, tokens_seen, train_losses, val_losses)\n",
    "\n",
    "    # save cfg and checkpoint\n",
    "    training_utils.save_cfg_json(\n",
    "        cfg=cfg, \n",
    "        epoch=num_epochs, \n",
    "        global_step=global_step) \n",
    "    # DEBUG: temp disable \n",
    "    # training_utils.save_checkpoint(\n",
    "    #     model=model,\n",
    "    #     optimizer=optimizer,\n",
    "    #     cfg=cfg,\n",
    "    #     epoch=cfg['num_epochs'],\n",
    "    #     global_step=global_step,\n",
    "    # )\n",
    "    training_utils.save_results(cfg,\n",
    "        train_losses, val_losses, tokens_seen, global_step)\n",
    "    \n",
    "\n",
    "    # return some results\n",
    "    return {\n",
    "        \"final_train_loss\": float(train_losses[-1]),\n",
    "        \"final_val_loss\": float(val_losses[-1]),\n",
    "        \"tokens_seen\": int(tokens_seen[-1]),\n",
    "        \"global_step\": int(global_step),\n",
    "    }\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24a02590",
   "metadata": {},
   "source": [
    "## 4. EXPERIMENT 1: basic params"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b89b07c1",
   "metadata": {},
   "source": [
    "### configs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5045ad1e",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg = gpt2small_config.RUN_CONFIG\n",
    "cfg\n",
    "cfg2 = deepcopy(cfg)\n",
    "cfg2['run_name'] = \"gpt2_devicetest\"\n",
    "cfg2['num_epochs']=2 # just to check things\n",
    "# to force fail on cpu only\n",
    "cfg2['device_name'] = \"cuda\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00d92cf5",
   "metadata": {},
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f2923e79",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cfg2['device_name']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ade54a77",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DEVICE: initial device before adjustment: cuda\n",
      "DEVICE: device AFTER adjustment: cpu\n",
      "{'run_name': 'gpt2_devicetest', 'description': 'gpt2-small on the verdict', 'device_name': 'cpu', 'model_name': 'gpt2-small', 'model_config': {'vocab_size': 50257, 'context_length': 256, 'emb_dim': 768, 'n_heads': 12, 'n_layers': 12, 'drop_rate': 0.1, 'qkv_bias': False, 'weight_tying': False}, 'tokenizer': 'gpt2', 'pretrained': False, 'training_file': '/home/markb/llm-from-scratch/data/the-verdict.txt', 'val_file': '', 'test_file': '', 'val_ratio': 0.1, 'test_ratio': 0.0, 'stride': 256, 'batch_size': 2, 'lr': 0.0004, 'weight_decay': 0.1, 'num_epochs': 2, 'seed': 123, 'output_dir': '/home/markb/llm-from-scratch/output'}\n",
      "Total number of parameters: 162419712\n",
      "weight_tying flag: False\n",
      "same object?: False\n",
      "out_head.weight shape: torch.Size([50257, 768])\n",
      "tok_emb.weight shape: torch.Size([50257, 768])\n",
      "check_flag is True; output of train_file\n",
      "/home/markb/llm-from-scratch/data/the-verdict.txt\n",
      "Characters: 20479\n",
      "Tokens: 5145\n",
      "\n",
      "\n",
      "Show train_loader first entry (converted to text):\n",
      "I HAD always thought Jack Gisburn rather a cheap genius--though a good fellow enough--so it was no great surprise to me to hear that, in the height of his glory, he had dropped his painting, married a rich widow, and established himself in a villa on the Riviera. (Though I rather thought it would have been Rome or Florence.)  \"The height of his glory\"--that was what the women called it. I can hear Mrs. Gideon Thwing--his last Chicago sitter--deploring his unaccountable abdication. \"Of course it's going to send the value of my picture 'way up; but I don't think of that, Mr. Rickham--the loss to Arrt is all I think of.\" The word, on Mrs. Thwing's lips, multiplied its _rs_ as though they were reflected in an endless vista of mirrors. And it was not only the Mrs. Thwings who mourned. Had not the exquisite Hermia Croft, at the last Grafton Gallery show, stopped me before Gisburn's \"Moon-dancers\" to say, with tears in her eyes: \"We shall not look upon its like again\"?  Well!--\n",
      "Show val_loader first entry (converted to text):\n",
      "ue' collapsed like a house of cards. He didn't sneer, you understand, poor Stroud--he just lay there quietly watching, and on his lips, through the gray beard, I seemed to hear the question: 'Are you sure you know where you're coming out?'  \"If I could have painted that face, with that question on it, I should have done a great thing. The next greatest thing was to see that I couldn't--and that grace was given me. But, oh, at that minute, Rickham, was there anything on earth I wouldn't have given to have Stroud alive before me, and to hear him say: 'It's not too late--I'll show you how'?  \"It _was_ too late--it would have been, even if he'd been alive. I packed up my traps, and went down and told Mrs. Stroud. Of course I didn't tell her _that_--it would have been Greek to her. I simply said I couldn't paint him, that I was too moved. She rather liked the idea--she's so romantic! It was that that made her give me the donkey. But she was terribly upset at not getting the portrait--she\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[6]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mrun_training\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcfg2\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 68\u001b[39m, in \u001b[36mrun_training\u001b[39m\u001b[34m(cfg)\u001b[39m\n\u001b[32m     66\u001b[39m num_epochs = cfg[\u001b[33m'\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m'\u001b[39m]\n\u001b[32m     67\u001b[39m optimizer = training_utils.setup_optimizer(model, cfg)\n\u001b[32m---> \u001b[39m\u001b[32m68\u001b[39m train_losses, val_losses, tokens_seen, global_step = \u001b[43mtraining_utils\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtrain_model_simple\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     69\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     70\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     71\u001b[39m \u001b[43m    \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m=\u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     72\u001b[39m \u001b[43m    \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     73\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mdevice_name\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     74\u001b[39m \u001b[43m    \u001b[49m\u001b[43mnum_epochs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcfg\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mnum_epochs\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     75\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_freq\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     76\u001b[39m \u001b[43m    \u001b[49m\u001b[43meval_iter\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m5\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     77\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_context\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mEvery effort moves you\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     78\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtokenizer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtokenizer\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[38;5;66;03m# plot and save plot\u001b[39;00m\n\u001b[32m     82\u001b[39m epochs_tensor = torch.linspace(\u001b[32m0\u001b[39m, cfg[\u001b[33m'\u001b[39m\u001b[33mnum_epochs\u001b[39m\u001b[33m'\u001b[39m], \u001b[38;5;28mlen\u001b[39m(train_losses))\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm-from-scratch/src/llm_from_scratch/training/training_utils.py:178\u001b[39m, in \u001b[36mtrain_model_simple\u001b[39m\u001b[34m(model, train_loader, val_loader, optimizer, device, num_epochs, eval_freq, eval_iter, start_context, tokenizer)\u001b[39m\n\u001b[32m    175\u001b[39m global_step += \u001b[32m1\u001b[39m\n\u001b[32m    177\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m global_step % eval_freq == \u001b[32m0\u001b[39m:\n\u001b[32m--> \u001b[39m\u001b[32m178\u001b[39m     train_loss, val_loss = \u001b[43mevaluate_model\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    179\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mval_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43meval_iter\u001b[49m\n\u001b[32m    180\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    181\u001b[39m     train_losses.append(train_loss)\n\u001b[32m    182\u001b[39m     val_losses.append(val_loss)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm-from-scratch/src/llm_from_scratch/training/training_utils.py:197\u001b[39m, in \u001b[36mevaluate_model\u001b[39m\u001b[34m(model, train_loader, val_loader, device, eval_iter)\u001b[39m\n\u001b[32m    195\u001b[39m model.eval()\n\u001b[32m    196\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m torch.no_grad():\n\u001b[32m--> \u001b[39m\u001b[32m197\u001b[39m     train_loss = \u001b[43mcalc_loss_loader\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    198\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtrain_loader\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_batches\u001b[49m\u001b[43m=\u001b[49m\u001b[43meval_iter\u001b[49m\n\u001b[32m    199\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    200\u001b[39m     val_loss = calc_loss_loader(\n\u001b[32m    201\u001b[39m         val_loader, model, device, num_batches=eval_iter\n\u001b[32m    202\u001b[39m     )\n\u001b[32m    203\u001b[39m model.train()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm-from-scratch/src/llm_from_scratch/training/training_utils.py:126\u001b[39m, in \u001b[36mcalc_loss_loader\u001b[39m\u001b[34m(data_loader, model, device, num_batches)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i, (input_batch, target_batch) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(data_loader):\n\u001b[32m    125\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m i< num_batches:\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m         loss = \u001b[43mcalc_loss_batch\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    127\u001b[39m \u001b[43m            \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtarget_batch\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\n\u001b[32m    128\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    129\u001b[39m         total_loss += loss.item()\n\u001b[32m    130\u001b[39m     \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm-from-scratch/src/llm_from_scratch/training/training_utils.py:106\u001b[39m, in \u001b[36mcalc_loss_batch\u001b[39m\u001b[34m(input_batch, target_batch, model, device)\u001b[39m\n\u001b[32m    104\u001b[39m input_batch = input_batch.to(device)\n\u001b[32m    105\u001b[39m target_batch = target_batch.to(device)\n\u001b[32m--> \u001b[39m\u001b[32m106\u001b[39m logits=\u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    107\u001b[39m loss = torch.nn.functional.cross_entropy(\n\u001b[32m    108\u001b[39m     logits.flatten(\u001b[32m0\u001b[39m,\u001b[32m1\u001b[39m), target_batch.flatten()\n\u001b[32m    109\u001b[39m )\n\u001b[32m    110\u001b[39m \u001b[38;5;66;03m# print(f\"single batch loss is {loss}\")  # added to look at it\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llmenv-first/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llmenv-first/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llm-from-scratch/src/llm_from_scratch/models/gpt2.py:253\u001b[39m, in \u001b[36mGPTModel.forward\u001b[39m\u001b[34m(self, in_idx)\u001b[39m\n\u001b[32m    251\u001b[39m x = \u001b[38;5;28mself\u001b[39m.trf_blocks(x)\n\u001b[32m    252\u001b[39m x = \u001b[38;5;28mself\u001b[39m.final_norm(x)\n\u001b[32m--> \u001b[39m\u001b[32m253\u001b[39m logits = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mout_head\u001b[49m\u001b[43m(\u001b[49m\u001b[43mx\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    254\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m logits\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llmenv-first/lib/python3.12/site-packages/torch/nn/modules/module.py:1751\u001b[39m, in \u001b[36mModule._wrapped_call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1749\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._compiled_call_impl(*args, **kwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[32m   1750\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1751\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llmenv-first/lib/python3.12/site-packages/torch/nn/modules/module.py:1762\u001b[39m, in \u001b[36mModule._call_impl\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m   1757\u001b[39m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[32m   1758\u001b[39m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[32m   1759\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m._backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m._forward_pre_hooks\n\u001b[32m   1760\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[32m   1761\u001b[39m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[32m-> \u001b[39m\u001b[32m1762\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1764\u001b[39m result = \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[32m   1765\u001b[39m called_always_called_hooks = \u001b[38;5;28mset\u001b[39m()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/llmenv-first/lib/python3.12/site-packages/torch/nn/modules/linear.py:125\u001b[39m, in \u001b[36mLinear.forward\u001b[39m\u001b[34m(self, input)\u001b[39m\n\u001b[32m    124\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) -> Tensor:\n\u001b[32m--> \u001b[39m\u001b[32m125\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[43m.\u001b[49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c906f18b",
   "metadata": {},
   "source": [
    "## Experiment 1a: make sure that model really resets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7529c5c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#cfg2['run_name']=\"gpt2_basic_exp_1a\"\n",
    "#run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbf6b450",
   "metadata": {},
   "source": [
    "## Experiment 1b: try alternate text\n",
    "There are two rationales for this, one for this current work and one looking forward.\n",
    "1. For this current work, it is interesting to see if different corpora perform significantly differently. Both are open source short stories (or part of a short story, truncated to be similar length to the first, for the second). This is just a basic check to see if reasonably similar sources vary much. Note also the concern that the test set is simply the last part of each story; this could easily have different characteristics than the rest of the text. Visual inspection doesn't reveal anything crazy (like if the last part were an author's note with different words and style than earlier) - but this could obviously be quantified by looking at word frequency or ngram frequency, etc. Simply comparing loss curves (both training and validation) for these two stories allows a quick and dirty examination of the effect of source material, when the source material is similar. \n",
    "\n",
    "2. Longer run: rationale for this is that there is a concern that \"the-verdict\" text may have been part of the training set of GPT2. I found an \"open source\" text that is from ~2024/2025, so should not have been part of the ~2019 training of GPT2. This is not an issue here with training from scratch, but for continued pre-training and evaluation, it is. So the test here is to see if this alterate text performs similarly, so I can use it with continued pre-training experiments in the GPT2-small framework.  \n",
    "\n",
    "3. I expect minor some minor differences; these texts are sylistically quite different in many ways, which can affect training.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c3ee1d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2['run_name']=\"gpt2_basic_exp_1b\"\n",
    "cfg2['description']=\"gpt2 with the adjusted watch story\"\n",
    "# \"training_file\": \"/home/markb/llm-from-scratch/data/the-verdict.txt\"\n",
    "cfg2['training_file'] = \"/home/markb/llm-from-scratch/data/The-watch-story-adj-smaller-2.txt\"\n",
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "837ec5f1",
   "metadata": {},
   "source": [
    "### RESULTS  \n",
    "1. Curves are quite similar with the two texts.  \n",
    "2. With identical number of tokens seen, have somewhat larger training loss with the watch vs the verdict and slightly higher validation loss.  \n",
    "3. Implications:  \n",
    "    a. these texts do not appear to be some crazy texts that would mess with interpretation in these simple basic frameworks.  \n",
    "    b. these texts can both be used later on for looking at the pre-trained models. The first text may have been part of the training set for the GPT2-small, but the second text is well after the training cutoff, so almost certainly was not."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b540d142",
   "metadata": {},
   "source": [
    "## Experiment 2: change stride to do more training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e9752dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2['run_name']=\"gpt2_basic_exp_2\"\n",
    "cfg2['stride']=128\n",
    "cfg2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a3f3de1",
   "metadata": {},
   "source": [
    "### run model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a2039ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f34355a1",
   "metadata": {},
   "source": [
    "## Experiment 3: make a much smaller model 2 layers, 2 heads, and emb_dim of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ede47b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2['run_name']=\"gpt2_basic_exp_3\"\n",
    "cfg2['model_config'][\"emb_dim\"]= 256         # Embedding dimension\n",
    "cfg2['model_config'][\"n_heads\"]= 2          # Number of attention heads\n",
    "cfg2['model_config'][\"n_layers\"]= 2          # Number of layers\n",
    "cfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51bf687e",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7e32207",
   "metadata": {},
   "source": [
    "## Experiment 4: do more epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7edfee44",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2['run_name']=\"gpt2_basic_exp_4\"\n",
    "cfg2['num_epochs']=8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e402ecaa",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6f21e1f",
   "metadata": {},
   "source": [
    "## Experiment 5: mini-model, 2 layers, 4 heads per layer, 6 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e24b3e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2['run_name']=\"gpt2_basic_exp_5\"\n",
    "cfg2['num_epochs']=6\n",
    "cfg2['model_config']['n_layers']=2\n",
    "cfg2['model_config']['n_heads']=4\n",
    "cfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a64d796",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec994124",
   "metadata": {},
   "source": [
    "## Experiment 6: mini-model, 2 layers, 8 heads per layer, epochs = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a43e1728",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2['run_name']=\"gpt2_basic_exp_6\"\n",
    "cfg2['num_epochs']=6\n",
    "cfg2['model_config']['n_layers']=2\n",
    "cfg2['model_config']['n_heads']=8\n",
    "cfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eed90a17",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e398512",
   "metadata": {},
   "source": [
    "## Experiment 7: mini-model, 8 layers, 2 heads per layer, 6 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1589f49c",
   "metadata": {},
   "outputs": [],
   "source": [
    "cfg2['run_name']=\"gpt2_basic_exp_6\"\n",
    "#cfg2['model_config']['weight_tying']=True\n",
    "cfg2['num_epochs']=6\n",
    "cfg2['model_config']['n_layers']=8\n",
    "cfg2['model_config']['n_heads']=2\n",
    "#cfg2['model_config']['emb_dim']=384\n",
    "cfg2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4556c22b",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6372fb4b",
   "metadata": {},
   "source": [
    "## Experiment 8: mini-model, 8 layers, 2 heads per layer, emb_dim=64 6 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14c83dad",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Experiment 7: mini-model, 8 layers, 2 heads per layer, 6 epochs\n",
    "cfg2['run_name']=\"gpt2_basic_exp_6\"\n",
    "#cfg2['model_config']['weight_tying']=True\n",
    "cfg2['num_epochs']=6\n",
    "cfg2['model_config']['n_layers']=8\n",
    "cfg2['model_config']['n_heads']=2\n",
    "cfg2['model_config']['emb_dim']=64\n",
    "cfg2\n",
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8eba972f",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "78863600",
   "metadata": {},
   "source": [
    "## Experiment 9: mini-model, 8 layers, 2 heads per layer, emb_dim=64 12 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99ee7c2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg2['run_name']=\"gpt2_basic_exp_9\"\n",
    "#cfg2['model_config']['weight_tying']=True\n",
    "cfg2['num_epochs']=12\n",
    "cfg2['model_config']['n_layers']=8\n",
    "cfg2['model_config']['n_heads']=2\n",
    "cfg2['model_config']['emb_dim']=64\n",
    "cfg2\n",
    "run_training(cfg2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b63ca1ac",
   "metadata": {},
   "source": [
    "## Experiment 10: mini-model, 8 layers, 8 heads per layer, emb_dim=768 6 epochs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1a5462d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "cfg2['run_name']=\"gpt2_basic_exp_10\"\n",
    "#cfg2['model_config']['weight_tying']=True\n",
    "cfg2['num_epochs']=6\n",
    "cfg2['model_config']['n_layers']=8\n",
    "cfg2['model_config']['n_heads']=8\n",
    "cfg2['model_config']['emb_dim']=768\n",
    "cfg2\n",
    "run_training(cfg2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "llmenv-first",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
